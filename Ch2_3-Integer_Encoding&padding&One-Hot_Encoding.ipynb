{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규표현식 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "r=re.compile(\"ab?c\")\n",
    "r.search(\"abbc\") # 아무런 결과도 출력되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 4), match='abc'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "r=re.compile(\"ab+c\")\n",
    "r.search(\"kabc\") # 아무런 결과도 출력되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 4), match='abc'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.search(\"kabc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사과', '딸기', '수박', '메론', '바나나']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text=\"사과 딸기 수박 메론 바나나\"\n",
    "re.split(\" \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010', '1234', '1234', '30']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text=\n",
    "\"\"\"\n",
    "이름 : 김철수\n",
    "전화번호 : 010 - 1234 - 1234\n",
    "나이 : 30\n",
    "성별 : 남\n",
    "\"\"\"  \n",
    "re.findall(\"\\d+\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수 인코딩\n",
    "\n",
    "컴퓨터는 텍스트보다는 숫자를 더 잘 처리 할 수 있습니다. 이를 위해 자연어 처리에서는 텍스트를 숫자로 바꾸는 여러가지 기법들이 있다.\n",
    "##### 각 단어를 고유한 정수에 맵핑(mapping)시키는 전처리 작업\n",
    "보통은 전처리 또는 빈도수가 높은 단어들만 사용하기 위해서 단어에 대한 빈도수를 기준으로 정렬한 뒤에 부여한다.\n",
    "\n",
    "### 1. 정수 인코딩\n",
    "\n",
    "단어에 정수를 부여하는 방법 중 하나로 단어를 빈도수 순으로 정렬한 단어 집합(vocabulary)을 만들고, 빈도수가 높은 순서대로 차례로 낮은 숫자부터 정수를 부여하는 방법이 있습니다. 이해를 돕기위해 단어의 빈도수가 적당하게 분포되도록 의도적으로 만든 텍스트 데이터를 가지고 실습해보겠습니다.\n",
    "\n",
    "#### 1) dictionary 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
    "\n",
    "text = sent_tokenize(text)\n",
    "\n",
    "vocab = {} # 파이썬의 dictionary 자료형\n",
    "sentences = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in text:\n",
    "    sentence = word_tokenize(i) # 단어 토큰화를 수행합니다.\n",
    "    result = []\n",
    "\n",
    "    for word in sentence: \n",
    "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄입니다.\n",
    "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거합니다.\n",
    "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거합니다.\n",
    "                result.append(word)\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 0 \n",
    "                vocab[word] += 1\n",
    "    sentences.append(result) \n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "# 단어를 키로 단어에 대한 빈도수가 값으로 저장되어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
    "\n",
    "word_to_index = {}\n",
    "i=0\n",
    "for (word, frequency) in vocab_sorted :\n",
    "    if frequency > 1 : # 정제(Cleaning) 챕터에서 언급했듯이 빈도수가 적은 단어는 제외한다.\n",
    "        i=i+1\n",
    "        word_to_index[word] = i\n",
    "vocab_size = 5\n",
    "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
    "for w in words_frequency:\n",
    "    del word_to_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Counter 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
     ]
    }
   ],
   "source": [
    "words = sum(sentences, []) #문장의 경계인 [,] 를 제거하고 단어들을 하나의 리스트로 만들자\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'barber': 8,\n",
       "         'person': 3,\n",
       "         'good': 1,\n",
       "         'huge': 5,\n",
       "         'knew': 1,\n",
       "         'secret': 6,\n",
       "         'kept': 4,\n",
       "         'word': 2,\n",
       "         'keeping': 2,\n",
       "         'driving': 1,\n",
       "         'crazy': 1,\n",
       "         'went': 1,\n",
       "         'mountain': 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter(words) # 파이썬의 Counter 모듈을 이용하면 단어의 모든 빈도를 쉽게 계산할 수 있습니다.\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab :\n",
    "    i = i+1\n",
    "    word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 케라스의 텍스트 전처리\n",
    "\n",
    "케라스의 전처리 도구인 토크나이저를 사용하기도 하는데, 사용 방법과 그 특징에 대해서 이해해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences) # fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성한다.\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩\n",
    "\n",
    "자연어 처리를 하다보면 각 문장(또는 문서)은 서로 길이가 다를 수 있습니다. 그런데 기계는 길이가 전부 동일한 문서들에 대해서는 하나의 행렬로 보고, 한꺼번에 묶어서 처리할 수 있습니다. 다시 말해 병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업이 필요할 때가 있습니다. 실습을 통해 이해해봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences) # fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성한다.\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(item) for item in encoded)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 긴 문장의 길이는 7 이기 때문에 7로 맞춘다.\n",
    "# 이와 같이 데이터에 특정 값을 채워서 데이터의 크기(shape)를 조정하는 것을 패딩(padding)이라고 합니다. 숫자 0을 사용하고 있다면 제로 패딩(zero padding)이라고 합니다.\n",
    "for item in encoded: # 각 문장에 대해서\n",
    "    while len(item) < max_len:   # max_len보다 작으면\n",
    "        item.append(0)\n",
    "\n",
    "padded_np = np.array(encoded)\n",
    "padded_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원-핫 인코딩(One-Hot Encoding)\n",
    "\n",
    "컴퓨터 또는 기계는 문자보다는 숫자를 더 잘 처리 할 수 있습니다. 이를 위해 자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법들이 있습니다. 원-핫 인코딩(One-Hot Encoding)은 그 많은 기법 중에서 단어를 표현하는 가장 기본적인 표현 방법이며, 머신 러닝, 딥 러닝을 하기 위해서는 반드시 배워야 하는 표현 방법입니다.\n",
    "\n",
    "ex) book은 150번, dog는 171번, love는 192번, books는 212번과 같이 부여할 수 있다.\n",
    "\n",
    "## 원-핫 인코딩이란?\n",
    "원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. \n",
    "\n",
    "(1) 각 단어에 고유한 인덱스를 부여합니다. (정수 인코딩)\n",
    "\n",
    "(2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt  \n",
    "okt=Okt()  \n",
    "token=okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "word2index={}\n",
    "for voca in token:\n",
    "     if voca not in word2index.keys():\n",
    "       word2index[voca]=len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "       one_hot_vector = [0]*(len(word2index))\n",
    "       index=word2index[word]\n",
    "       one_hot_vector[index]=1\n",
    "       return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\",word2index)"
   ]
  },
  {
   "attachments": {
    "%ED%99%94%EB%A9%B4%20%EC%BA%A1%EC%B2%98%202021-02-15%20000506.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 분리\n",
    "\n",
    "머신 러닝(딥 러닝) 모델에 데이터를 훈련시키기 위해서는 데이터를 적절히 분리하는 작업이 필요합니다.\n",
    "\n",
    "지도학습을 위한 데이터 분리 작업을 알아보자\n",
    "\n",
    "### 지도 학습\n",
    "![%ED%99%94%EB%A9%B4%20%EC%BA%A1%EC%B2%98%202021-02-15%20000506.png](attachment:%ED%99%94%EB%A9%B4%20%EC%BA%A1%EC%B2%98%202021-02-15%20000506.png)\n",
    "\n",
    "위와 같이 데이터가 20000개 있다고 가정했을 때 18000개의 데이터를 훈련용 데이터, 2000개의 데이터를 테스트 데이터로 분리해서 생각하자\n",
    "\n",
    "##### <훈련 데이터>\n",
    "X_train : 문제지 데이터\n",
    "\n",
    "y_train : 문제지에 대한 정답 데이터.\n",
    "\n",
    "##### <테스트 데이터>\n",
    "X_test : 시험지 데이터.\n",
    "\n",
    "y_test : 시험지에 대한 정답 데이터."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# zip 함수를 이용하여 분리하기\n",
    "X,y = zip(['a', 1], ['b', 2], ['c', 3])\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>메일 본문</th>\n",
       "      <th>스팸 메일 유무</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당신에게 드리는 마지막 혜택!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내일 뵐 수 있을지 확인 부탁드...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>도연씨. 잘 지내시죠? 오랜만입...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(광고) AI로 주가를 예측할 수 있다!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    메일 본문  스팸 메일 유무\n",
       "0        당신에게 드리는 마지막 혜택!         1\n",
       "1    내일 뵐 수 있을지 확인 부탁드...         0\n",
       "2    도연씨. 잘 지내시죠? 오랜만입...         0\n",
       "3  (광고) AI로 주가를 예측할 수 있다!         1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임을 이용하여 분리하기 \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "values = [['당신에게 드리는 마지막 혜택!', 1],\n",
    "['내일 뵐 수 있을지 확인 부탁드...', 0],\n",
    "['도연씨. 잘 지내시죠? 오랜만입...', 0],\n",
    "['(광고) AI로 주가를 예측할 수 있다!', 1]]\n",
    "columns = ['메일 본문', '스팸 메일 유무']\n",
    "\n",
    "df = pd.DataFrame(values, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "# Numpy를 이용하여 분리하기\n",
    "\n",
    "import numpy as np\n",
    "ar = np.arange(0,16).reshape((4,4))\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 분리하기\n",
    "\n",
    "#### 사이킷 런을 이용하여 분리하기\n",
    "\n",
    "사이킷 런은 학습용 테스트와 테스트용 데이터를 분리하게 해주는 train_test_split를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size : 테스트용 데이터 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
    "# train_size : 학습용 데이터의 개수를 지정한다. 1보다 작은 실수를 기재할 경우, 비율을 나타낸다.\n",
    "# random_state : 난수 시드\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "# 실습을 위해 임의로 X와 y가 이미 분리 된 데이터를 생성\n",
    "print(X)\n",
    "print(list(y)) #레이블 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)\n",
    "#3분의 1만 test 데이터로 지정.\n",
    "#random_state 지정으로 인해 순서가 섞인 채로 훈련 데이터와 테스트 데이터가 나눠진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
